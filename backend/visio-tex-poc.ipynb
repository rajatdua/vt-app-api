{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (2.1.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Collecting pillow\r\n",
      "  Obtaining dependency information for pillow from https://files.pythonhosted.org/packages/f4/5f/491dafc7bbf5a3cc1845dc0430872e8096eb9e2b6f8161509d124594ec2d/pillow-10.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading pillow-10.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.2 kB)\r\n",
      "Downloading pillow-10.4.0-cp311-cp311-macosx_11_0_arm64.whl (3.4 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m11.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: pillow\r\n",
      "Successfully installed pillow-10.4.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.11/site-packages (2.4.1)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from torch) (3.16.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.11/site-packages (from torch) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.11/site-packages (from torch) (1.13.2)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.11/site-packages (from torch) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from torch) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.11/site-packages (from torch) (2024.9.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pillow\n",
    "!pip install torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-13T07:03:25.644637Z",
     "start_time": "2024-09-13T07:03:22.073242Z"
    }
   },
   "id": "23dea60e3ad344d2"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.0.0\r\n",
      "Uninstalling numpy-2.0.0:\r\n",
      "  Would remove:\r\n",
      "    /Users/rajat/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/bin/f2py\r\n",
      "    /Users/rajat/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/bin/numpy-config\r\n",
      "    /Users/rajat/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages/numpy-2.0.0.dist-info/*\r\n",
      "    /Users/rajat/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages/numpy/*\r\n",
      "Proceed (Y/n)? ^C\r\n",
      "\u001B[31mERROR: Operation cancelled by user\u001B[0m\u001B[31m\r\n",
      "\u001B[0mRequirement already satisfied: numpy==2.0.0 in /Users/rajat/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages (2.0.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy\n",
    "!pip install numpy==2.0.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-13T07:27:25.573468Z",
     "start_time": "2024-09-13T07:27:15.240983Z"
    }
   },
   "id": "5964687b3f1a50c8"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow-heif in /Users/rajat/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages (0.20.0)\r\n",
      "Requirement already satisfied: pillow>=10.1.0 in /Users/rajat/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages (from pillow-heif) (10.4.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Collecting pyheif\r\n",
      "  Downloading pyheif-0.8.0.tar.gz (20 kB)\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Installing backend dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: cffi>=1.0.0 in /Users/rajat/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages (from pyheif) (1.17.1)\r\n",
      "Requirement already satisfied: pycparser in /Users/rajat/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages (from cffi>=1.0.0->pyheif) (2.22)\r\n",
      "Building wheels for collected packages: pyheif\r\n",
      "  Building wheel for pyheif (pyproject.toml) ... \u001B[?25lerror\r\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[31m×\u001B[0m \u001B[32mBuilding wheel for pyheif \u001B[0m\u001B[1;32m(\u001B[0m\u001B[32mpyproject.toml\u001B[0m\u001B[1;32m)\u001B[0m did not run successfully.\r\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\r\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[23 lines of output]\u001B[0m\r\n",
      "  \u001B[31m   \u001B[0m running bdist_wheel\r\n",
      "  \u001B[31m   \u001B[0m running build\r\n",
      "  \u001B[31m   \u001B[0m running build_py\r\n",
      "  \u001B[31m   \u001B[0m creating build/lib.macosx-10.9-universal2-cpython-311/pyheif\r\n",
      "  \u001B[31m   \u001B[0m copying pyheif/error.py -> build/lib.macosx-10.9-universal2-cpython-311/pyheif\r\n",
      "  \u001B[31m   \u001B[0m copying pyheif/transformations.py -> build/lib.macosx-10.9-universal2-cpython-311/pyheif\r\n",
      "  \u001B[31m   \u001B[0m copying pyheif/constants.py -> build/lib.macosx-10.9-universal2-cpython-311/pyheif\r\n",
      "  \u001B[31m   \u001B[0m copying pyheif/__init__.py -> build/lib.macosx-10.9-universal2-cpython-311/pyheif\r\n",
      "  \u001B[31m   \u001B[0m copying pyheif/reader.py -> build/lib.macosx-10.9-universal2-cpython-311/pyheif\r\n",
      "  \u001B[31m   \u001B[0m copying pyheif/writer.py -> build/lib.macosx-10.9-universal2-cpython-311/pyheif\r\n",
      "  \u001B[31m   \u001B[0m creating build/lib.macosx-10.9-universal2-cpython-311/pyheif/data\r\n",
      "  \u001B[31m   \u001B[0m copying pyheif/data/version.txt -> build/lib.macosx-10.9-universal2-cpython-311/pyheif/data\r\n",
      "  \u001B[31m   \u001B[0m running build_ext\r\n",
      "  \u001B[31m   \u001B[0m generating cffi module 'build/temp.macosx-10.9-universal2-cpython-311/_libheif_cffi.c'\r\n",
      "  \u001B[31m   \u001B[0m creating build/temp.macosx-10.9-universal2-cpython-311\r\n",
      "  \u001B[31m   \u001B[0m building '_libheif_cffi' extension\r\n",
      "  \u001B[31m   \u001B[0m creating build/temp.macosx-10.9-universal2-cpython-311/build/temp.macosx-10.9-universal2-cpython-311\r\n",
      "  \u001B[31m   \u001B[0m clang -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch arm64 -arch x86_64 -g -I/usr/local/include -I/usr/include -I/opt/local/include -I/opt/homebrew/include -I/Users/rajat/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/include -I/Library/Frameworks/Python.framework/Versions/3.11/include/python3.11 -c build/temp.macosx-10.9-universal2-cpython-311/_libheif_cffi.c -o build/temp.macosx-10.9-universal2-cpython-311/build/temp.macosx-10.9-universal2-cpython-311/_libheif_cffi.o\r\n",
      "  \u001B[31m   \u001B[0m build/temp.macosx-10.9-universal2-cpython-311/_libheif_cffi.c:574:14: fatal error: 'libheif/heif.h' file not found\r\n",
      "  \u001B[31m   \u001B[0m   574 |     #include <libheif/heif.h>\r\n",
      "  \u001B[31m   \u001B[0m       |              ^~~~~~~~~~~~~~~~\r\n",
      "  \u001B[31m   \u001B[0m 1 error generated.\r\n",
      "  \u001B[31m   \u001B[0m error: command '/usr/bin/clang' failed with exit code 1\r\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001B[31m  ERROR: Failed building wheel for pyheif\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[?25hFailed to build pyheif\r\n",
      "\u001B[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pyheif)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow-heif"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T14:38:11.694632Z",
     "start_time": "2024-11-02T14:38:04.947043Z"
    }
   },
   "id": "eb5b9dd5a8e9f18f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyheif\r\n",
      "  Using cached pyheif-0.8.0.tar.gz (20 kB)\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Installing backend dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: cffi>=1.0.0 in /Users/rajat/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages (from pyheif) (1.17.1)\r\n",
      "Requirement already satisfied: pycparser in /Users/rajat/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages (from cffi>=1.0.0->pyheif) (2.22)\r\n",
      "Building wheels for collected packages: pyheif\r\n",
      "  Building wheel for pyheif (pyproject.toml) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for pyheif: filename=pyheif-0.8.0-cp311-cp311-macosx_10_9_universal2.whl size=45604 sha256=b374e52a3e997924f442760858a92b97db712345a796ee86a816b6f065679975\r\n",
      "  Stored in directory: /Users/rajat/Library/Caches/pip/wheels/3f/21/0a/b2ed0edff848cc99a77415f8fd175fc453e34a78f64145ea19\r\n",
      "Successfully built pyheif\r\n",
      "Installing collected packages: pyheif\r\n",
      "Successfully installed pyheif-0.8.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyheif"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T18:17:15.342578Z",
     "start_time": "2024-11-02T18:17:07.462594Z"
    }
   },
   "id": "c51a02deb71c095a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:23.456817Z",
     "start_time": "2024-11-03T14:05:22.943520Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/rajat/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 🚀 2024-9-13 Python-3.11.4 torch-2.4.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n",
      "/Users/rajat/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bounding_box': [2453, 1081, 2623, 2205], 'confidence': 0.9202294945716858}, {'bounding_box': [2825, 936, 3024, 2210], 'confidence': 0.911090612411499}, {'bounding_box': [3097, 1139, 3380, 2194], 'confidence': 0.9089668989181519}, {'bounding_box': [1119, 1123, 1329, 2281], 'confidence': 0.8971620202064514}, {'bounding_box': [2700, 1037, 2831, 2212], 'confidence': 0.8963306546211243}, {'bounding_box': [912, 1182, 1198, 2247], 'confidence': 0.8920981287956238}, {'bounding_box': [1723, 1114, 1890, 2254], 'confidence': 0.8875489234924316}, {'bounding_box': [2074, 1044, 2264, 2228], 'confidence': 0.8874149918556213}, {'bounding_box': [2250, 1235, 2354, 2208], 'confidence': 0.87773597240448}, {'bounding_box': [1504, 1135, 1649, 2236], 'confidence': 0.8744417428970337}, {'bounding_box': [668, 1170, 876, 2216], 'confidence': 0.8736534118652344}, {'bounding_box': [1633, 1272, 1757, 2254], 'confidence': 0.8725700974464417}, {'bounding_box': [1875, 1168, 2016, 2224], 'confidence': 0.8719338178634644}, {'bounding_box': [1536, 2789, 1658, 3017], 'confidence': 0.8576330542564392}, {'bounding_box': [2817, 2816, 3007, 3024], 'confidence': 0.8575521111488342}, {'bounding_box': [1419, 1141, 1563, 2251], 'confidence': 0.8523808121681213}, {'bounding_box': [2986, 1067, 3135, 2190], 'confidence': 0.8434074521064758}, {'bounding_box': [2347, 1240, 2457, 2196], 'confidence': 0.8317003846168518}, {'bounding_box': [3348, 1352, 3515, 2165], 'confidence': 0.8302294015884399}, {'bounding_box': [545, 1090, 767, 2212], 'confidence': 0.8038949966430664}, {'bounding_box': [3554, 2801, 3801, 3022], 'confidence': 0.8025251030921936}, {'bounding_box': [998, 2848, 1134, 3023], 'confidence': 0.793927788734436}, {'bounding_box': [2014, 2762, 2130, 3013], 'confidence': 0.7838168144226074}, {'bounding_box': [2002, 1277, 2088, 2216], 'confidence': 0.7837032675743103}, {'bounding_box': [1443, 2742, 1533, 3024], 'confidence': 0.77789705991745}, {'bounding_box': [2624, 1062, 2698, 2198], 'confidence': 0.769428014755249}, {'bounding_box': [481, 0, 681, 382], 'confidence': 0.7675371766090393}, {'bounding_box': [836, 2871, 992, 3019], 'confidence': 0.7584771513938904}, {'bounding_box': [2273, 2898, 2425, 3018], 'confidence': 0.741851806640625}, {'bounding_box': [778, 1186, 965, 2199], 'confidence': 0.7101526260375977}, {'bounding_box': [674, 0, 869, 374], 'confidence': 0.7071013450622559}, {'bounding_box': [3269, 2491, 3405, 3020], 'confidence': 0.6894485354423523}, {'bounding_box': [1274, 1356, 1394, 2259], 'confidence': 0.6798698902130127}, {'bounding_box': [3123, 2832, 3212, 3024], 'confidence': 0.6656959652900696}, {'bounding_box': [1907, 2853, 2006, 3022], 'confidence': 0.6624164581298828}, {'bounding_box': [1319, 1251, 1484, 2251], 'confidence': 0.6274592876434326}, {'bounding_box': [1558, 3, 1737, 374], 'confidence': 0.6195817589759827}, {'bounding_box': [3373, 2553, 3502, 3022], 'confidence': 0.6124943494796753}, {'bounding_box': [1783, 2496, 1900, 3022], 'confidence': 0.6085751056671143}, {'bounding_box': [2495, 2903, 2614, 3021], 'confidence': 0.5949525237083435}, {'bounding_box': [1794, 2753, 1896, 3006], 'confidence': 0.574337363243103}, {'bounding_box': [2608, 2879, 2720, 3018], 'confidence': 0.5631383657455444}, {'bounding_box': [3443, 2557, 3555, 3016], 'confidence': 0.526303231716156}, {'bounding_box': [287, 6, 424, 419], 'confidence': 0.489766389131546}, {'bounding_box': [1891, 0, 2073, 377], 'confidence': 0.4731287956237793}, {'bounding_box': [1427, 5, 1633, 373], 'confidence': 0.46199989318847656}, {'bounding_box': [2444, 1087, 2824, 2215], 'confidence': 0.45700645446777344}, {'bounding_box': [401, 1306, 653, 2268], 'confidence': 0.4520933926105499}, {'bounding_box': [976, 1, 1169, 376], 'confidence': 0.41974255442619324}, {'bounding_box': [902, 0, 1046, 375], 'confidence': 0.39820805191993713}, {'bounding_box': [1175, 2856, 1280, 3018], 'confidence': 0.39059531688690186}, {'bounding_box': [2196, 2633, 2271, 3011], 'confidence': 0.36747801303863525}, {'bounding_box': [1703, 0, 1942, 370], 'confidence': 0.35398170351982117}, {'bounding_box': [2389, 2550, 2503, 3013], 'confidence': 0.34615105390548706}, {'bounding_box': [2149, 0, 2305, 371], 'confidence': 0.32807767391204834}, {'bounding_box': [3202, 2832, 3273, 3010], 'confidence': 0.3217083513736725}, {'bounding_box': [2314, 0, 2470, 372], 'confidence': 0.3094497323036194}, {'bounding_box': [2228, 0, 2373, 375], 'confidence': 0.30016714334487915}, {'bounding_box': [1276, 9, 1479, 366], 'confidence': 0.29931125044822693}, {'bounding_box': [1329, 2871, 1445, 3011], 'confidence': 0.29864534735679626}, {'bounding_box': [2520, 0, 2661, 365], 'confidence': 0.2808282971382141}, {'bounding_box': [2882, 0, 3008, 364], 'confidence': 0.27344033122062683}, {'bounding_box': [2584, 0, 2706, 362], 'confidence': 0.26688912510871887}, {'bounding_box': [2411, 0, 2564, 370], 'confidence': 0.26667144894599915}, {'bounding_box': [2006, 1, 2183, 373], 'confidence': 0.26589685678482056}, {'bounding_box': [818, 5, 955, 365], 'confidence': 0.25925278663635254}, {'bounding_box': [0, 1538, 75, 2054], 'confidence': 0.25072258710861206}]\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from pillow_heif import register_heif_opener\n",
    "\n",
    "from app.core.detect import read_file_local, get_spine_regions\n",
    "import torch\n",
    "\n",
    "register_heif_opener()\n",
    "\n",
    "\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='./app/api/helpers/best.pt')\n",
    "image_path = 'simple-example-2.jpeg'\n",
    "# image_path = 'au-1.HEIC'\n",
    " # Read the image file\n",
    "img = read_file_local(image_path)\n",
    "\n",
    "# Detect book spines using YOLOv5\n",
    "results = model(img)\n",
    "\n",
    "# Get bounding boxes for detected objects (book spines)\n",
    "spine_regions = get_spine_regions(results)\n",
    "\n",
    "print(spine_regions);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pillow_heif\n",
    "\n",
    "def draw_bounding_boxes_cv2(image_path, boxes):\n",
    "    # Read the image with Pillow if it's HEIC, otherwise with OpenCV\n",
    "    if image_path.lower().endswith('.heic'):\n",
    "        heif_file = pillow_heif.open_heif(image_path)\n",
    "        (img_width, img_height) = heif_file.size\n",
    "        img = Image.frombytes(\n",
    "            \"RGB\",\n",
    "            (img_width, img_height),\n",
    "            heif_file.data,\n",
    "        )\n",
    "        img = np.array(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # Convert from RGB to BGR\n",
    "    else:\n",
    "        img = cv2.imread(image_path)\n",
    "    \n",
    "    # Ensure the image was loaded correctly\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image could not be loaded. Please check the file path and format.\")\n",
    "    \n",
    "    # Loop through all bounding boxes and draw them on the image\n",
    "    for box in boxes:\n",
    "        # Get the bounding box coordinates\n",
    "        bbox = box['bounding_box']\n",
    "        confidence = box['confidence']\n",
    "        \n",
    "        # Draw the bounding box as a rectangle on the image (x1, y1, x2, y2)\n",
    "        cv2.rectangle(img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 3)\n",
    "\n",
    "        # Optionally, add the confidence score as text\n",
    "        cv2.putText(img, f\"{confidence:.2f}\", (bbox[0], bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "    \n",
    "    # Show or save the result\n",
    "    cv2.imshow('Image with bounding boxes', img)\n",
    "    cv2.imwrite('output_with_boxes_cv2-3.jpg', img)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Test the function\n",
    "draw_bounding_boxes_cv2(image_path, spine_regions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T14:05:27.641554Z",
     "start_time": "2024-11-03T14:05:27.367600Z"
    }
   },
   "id": "1c39caccaa64aeab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "OCR"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70ed8c50e60eed4a"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "sees ‘\n",
      "tractor f22 ¢ {ie\n",
      "yaa 2245 comiigts\n",
      "z EI\n"
     ]
    },
    {
     "ename": "TesseractError",
     "evalue": "(1, 'Estimating resolution as 195 Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTesseractError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m most_likely_angle_rotated_img \u001B[38;5;241m=\u001B[39m rotate_image(inverted_img, \u001B[38;5;241m90\u001B[39m)\n\u001B[1;32m      8\u001B[0m text \u001B[38;5;241m=\u001B[39m get_ocr_text(most_likely_angle_rotated_img)\n\u001B[0;32m---> 10\u001B[0m rotation \u001B[38;5;241m=\u001B[39m \u001B[43mfind_correct_orientation\u001B[49m\u001B[43m(\u001B[49m\u001B[43minverted_img\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m rotated \u001B[38;5;241m=\u001B[39m rotate_image(inverted_img, rotation)\n\u001B[1;32m     12\u001B[0m text2 \u001B[38;5;241m=\u001B[39m get_ocr_text(rotated)\n",
      "File \u001B[0;32m~/Repositories/au/vt-app-api/backend/app/core/detect.py:56\u001B[0m, in \u001B[0;36mfind_correct_orientation\u001B[0;34m(image)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_correct_orientation\u001B[39m(image):\n\u001B[0;32m---> 56\u001B[0m     osd \u001B[38;5;241m=\u001B[39m \u001B[43mpytesseract\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage_to_osd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     57\u001B[0m     rotation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m([line \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m osd\u001B[38;5;241m.\u001B[39msplitlines() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRotate:\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m line][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m rotation\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages/pytesseract/pytesseract.py:621\u001B[0m, in \u001B[0;36mimage_to_osd\u001B[0;34m(image, lang, config, nice, output_type, timeout)\u001B[0m\n\u001B[1;32m    618\u001B[0m config \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m--psm 0 \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    619\u001B[0m args \u001B[38;5;241m=\u001B[39m [image, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mosd\u001B[39m\u001B[38;5;124m'\u001B[39m, lang, config, nice, timeout]\n\u001B[0;32m--> 621\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m{\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[43m    \u001B[49m\u001B[43mOutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBYTES\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_and_get_output\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[43m    \u001B[49m\u001B[43mOutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDICT\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mosd_to_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_and_get_output\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    624\u001B[0m \u001B[43m    \u001B[49m\u001B[43mOutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSTRING\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_and_get_output\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    625\u001B[0m \u001B[43m\u001B[49m\u001B[43m}\u001B[49m\u001B[43m[\u001B[49m\u001B[43moutput_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages/pytesseract/pytesseract.py:624\u001B[0m, in \u001B[0;36mimage_to_osd.<locals>.<lambda>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    618\u001B[0m config \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m--psm 0 \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    619\u001B[0m args \u001B[38;5;241m=\u001B[39m [image, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mosd\u001B[39m\u001B[38;5;124m'\u001B[39m, lang, config, nice, timeout]\n\u001B[1;32m    621\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m    622\u001B[0m     Output\u001B[38;5;241m.\u001B[39mBYTES: \u001B[38;5;28;01mlambda\u001B[39;00m: run_and_get_output(\u001B[38;5;241m*\u001B[39m(args \u001B[38;5;241m+\u001B[39m [\u001B[38;5;28;01mTrue\u001B[39;00m])),\n\u001B[1;32m    623\u001B[0m     Output\u001B[38;5;241m.\u001B[39mDICT: \u001B[38;5;28;01mlambda\u001B[39;00m: osd_to_dict(run_and_get_output(\u001B[38;5;241m*\u001B[39margs)),\n\u001B[0;32m--> 624\u001B[0m     Output\u001B[38;5;241m.\u001B[39mSTRING: \u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[43mrun_and_get_output\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    625\u001B[0m }[output_type]()\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages/pytesseract/pytesseract.py:352\u001B[0m, in \u001B[0;36mrun_and_get_output\u001B[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001B[0m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m save(image) \u001B[38;5;28;01mas\u001B[39;00m (temp_name, input_filename):\n\u001B[1;32m    342\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    343\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_filename\u001B[39m\u001B[38;5;124m'\u001B[39m: input_filename,\n\u001B[1;32m    344\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput_filename_base\u001B[39m\u001B[38;5;124m'\u001B[39m: temp_name,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    349\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m'\u001B[39m: timeout,\n\u001B[1;32m    350\u001B[0m     }\n\u001B[0;32m--> 352\u001B[0m     \u001B[43mrun_tesseract\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    353\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _read_output(\n\u001B[1;32m    354\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput_filename_base\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mextsep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mextension\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    355\u001B[0m         return_bytes,\n\u001B[1;32m    356\u001B[0m     )\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/app-FNN-Bqnv-py3.11/lib/python3.11/site-packages/pytesseract/pytesseract.py:284\u001B[0m, in \u001B[0;36mrun_tesseract\u001B[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001B[0m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m timeout_manager(proc, timeout) \u001B[38;5;28;01mas\u001B[39;00m error_string:\n\u001B[1;32m    283\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m proc\u001B[38;5;241m.\u001B[39mreturncode:\n\u001B[0;32m--> 284\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m TesseractError(proc\u001B[38;5;241m.\u001B[39mreturncode, get_errors(error_string))\n",
      "\u001B[0;31mTesseractError\u001B[0m: (1, 'Estimating resolution as 195 Warning. Invalid resolution 0 dpi. Using 70 instead. Too few characters. Skipping this page Error during processing.')"
     ]
    }
   ],
   "source": [
    "from app.core.detect import find_correct_orientation, preprocess_img, get_ocr_text, rotate_image\n",
    "import spacy\n",
    "\n",
    "\n",
    "inverted_img = preprocess_img(img, spine_regions[0]['bounding_box'])\n",
    "\n",
    "most_likely_angle_rotated_img = rotate_image(inverted_img, 90)\n",
    "text = get_ocr_text(most_likely_angle_rotated_img)\n",
    "\n",
    "rotation = find_correct_orientation(inverted_img)\n",
    "rotated = rotate_image(inverted_img, rotation)\n",
    "text2 = get_ocr_text(rotated)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_book_titles_nlp(ocr_text):\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(ocr_text)\n",
    "    \n",
    "    # Define a list to hold potential book titles\n",
    "    book_titles = []\n",
    "\n",
    "    for sent in doc.sents:  # Iterate over sentences\n",
    "        # Check for noun phrases (likely candidates for titles)\n",
    "        for np in sent.noun_chunks:\n",
    "            # Simple heuristic: Check if the noun phrase has at least two capitalized words\n",
    "            if len(np) > 1 and all(word[0].isupper() for word in np.text.split()):\n",
    "                book_titles.append(np.text)\n",
    "\n",
    "    return list(set(book_titles))  # Return unique titles\n",
    "\n",
    "# Extract book titles\n",
    "book_titles = extract_book_titles_nlp(text)\n",
    "title = ' '.join(book_titles)\n",
    "\n",
    "# Extract book titles 2\n",
    "book_titles2 = extract_book_titles_nlp(text2)\n",
    "title2 = ' '.join(book_titles2)\n",
    "\n",
    "print(title)\n",
    "print(title2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T12:07:55.458716Z",
     "start_time": "2024-11-02T12:07:54.678197Z"
    }
   },
   "id": "54f19b95a99ed17a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from app.core.detect import read_file_local\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "with open('simple-example-2-res.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "image_path = 'simple-example-2.jpeg'\n",
    "img = read_file_local(image_path)\n",
    "\n",
    "# Loop through each item in the JSON data\n",
    "for item in data['books']:\n",
    "    vertices = item['vertices']\n",
    "    \n",
    "    # Convert string vertices to integer tuples\n",
    "    points = [tuple(map(int, v.strip(\"()\").split(','))) for v in vertices]\n",
    "    \n",
    "    # Extract top-left and bottom-right points based on the min/max of vertices\n",
    "    x_min = min([p[0] for p in points])\n",
    "    y_min = min([p[1] for p in points])\n",
    "    x_max = max([p[0] for p in points])\n",
    "    y_max = max([p[1] for p in points])\n",
    "    \n",
    "    # Draw rectangle\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "# Show or save the result\n",
    "cv2.imshow(\"Image with Rectangle\", img)\n",
    "cv2.imwrite('simple-example-2-rec.jpg', img)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-01T09:17:56.740080Z",
     "start_time": "2024-11-01T09:17:52.218946Z"
    }
   },
   "id": "6ab9e53894f95798"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ark 76.235\n",
      "andede barn Tuvesson : Tomat , tomat\n",
      "rig\n",
      "nok\n",
      "COBOLT\n",
      "83.8 Emil Ferris\n",
      "Kathrine 72 Strøbek\n",
      "Nedrejord : . Niels Niels\n",
      "Forbryder og Strø\n",
      "straf Sh 78.797\n",
      "Rebecca Yarros\n",
      ": Fourth Solvej Ba\n",
      "wing\n",
      "64.17 Julia\n",
      ": My favorite thing is\n",
      "monsters Book 2 Hallgrímur\n",
      "38.44 Sundhedsfremme , forebyggelse og rehabilitering\n",
      "37.363 Karina Engelund Mathiasen : Fra specialpædagogik til pædagogik 74.6\n",
      "83 83 Barbara Kingsolver : Demon Copperhead\n",
      "46.4 Samsø 111 steder på Samsø som du skal se\n",
      "Klara Witt : Jeg finder dig i Rom\n",
      "37.14796 Idræt i skolen 99.4 E\n",
      "83.8 Sylvia Plath : The bell jar\n",
      "Det Kronede 78.18 Deni\n",
      "Hjerte / Bind 2\n",
      "FREDRIK\n",
      "BACKMANN\n",
      "UVIRKELIGHEDER\n",
      "Abba ABBA\n",
      "78.652 Carl Orff\n",
      "CAPPELLA\n",
      "Carmina burana\n",
      "Christina He\n",
      "99.4 Mu\n",
      "85.3\n",
      "Colleen Hoover : De\n",
      "ng\n",
      "magic\n",
      "of\n",
      "tidying 99.4\n",
      "up Kløvedal , Lærke Lærke\n",
      "Jodi Thomas RANSOM\n",
      "CANYON 1 Mads Anand\n",
      "13.16 Nicklas Brendborg : Vanedyr\n",
      "Kløvedal : Sømærke\n",
      "J.P. Jacobsen N\n",
      "78.797 Inger laus\n",
      "67.7\n",
      "RJÆTTET 38.79\n",
      "ND\n",
      "FLOPO021\n",
      "Mase\n",
      "Albeck EN\n",
      "Sussi\n",
      "Abeck 96.7\n",
      "Lillan Dusinet futo\n",
      "Albeck L. G. Davis\n",
      "FENGSIEN\n",
      "98.218 Puk Damsgård\n",
      "Andersen : Drageland\n",
      "61.4\n",
      "Praksisforskning på\n",
      "sundhedsområdet 83.8\n",
      "64.7 Pernille\n",
      "Oldgaard : Overblik\n",
      "98.29\n",
      "Junichiro Tanizaki : Til\n",
      "skyggernes pris\n",
      "Georgette\n",
      "Heyer : Fine\n",
      "fornemmelser Kurt Vo\n",
      "Gertrud\n",
      "Hellbrand :\n",
      "Rød hibiscus\n",
      "9'7\n",
      ": Barnepigen\n",
      "99.1\n",
      "Peter Durrie\n",
      "Stærkere\n",
      "samvær med\n",
      "højtlæsning\n",
      "= 2\n",
      "ND\n",
      "13.16 Nick\n",
      "Kurt Vonnes\n",
      "96.7\n",
      "04.3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('simple-example-2-res.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    \n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "\n",
    "def parse_vertices(vertices: List[str]) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Convert vertex strings to a list of (x, y) tuples.\"\"\"\n",
    "    return [tuple(map(int, v.strip(\"()\").split(\",\"))) for v in vertices]\n",
    "\n",
    "def get_average_x(vertices: List[Tuple[int, int]]) -> float:\n",
    "    \"\"\"Calculate the average x-coordinate from vertices.\"\"\"\n",
    "    x_coords = [vertex[0] for vertex in vertices]\n",
    "    return np.mean(x_coords)\n",
    "\n",
    "def group_vertical_lines(data: List[Dict], epsilon: float) -> List[Dict]:\n",
    "    \"\"\"Filter descriptions that are vertically aligned within epsilon distance.\"\"\"\n",
    "    parsed_data=[]\n",
    "    for item in data:\n",
    "        parsed_data.append({\n",
    "            \"description\": item[\"description\"],\n",
    "            \"vertices\": parse_vertices(item[\"vertices\"]),\n",
    "            \"avg_x\": get_average_x(parse_vertices(item[\"vertices\"]))\n",
    "        })\n",
    "    # \n",
    "    # filtered_data = []\n",
    "    # skip_indices = set()\n",
    "    # \n",
    "    # for i, item in enumerate(parsed_data):\n",
    "    #     if i in skip_indices:\n",
    "    #         continue\n",
    "    #     # Find all descriptions within epsilon distance in avg_x\n",
    "    #     close_items = [\n",
    "    #         j for j, other in enumerate(parsed_data)\n",
    "    #         if j != i and abs(item[\"avg_x\"] - other[\"avg_x\"]) <= epsilon\n",
    "    #     ]\n",
    "    #     if not close_items:\n",
    "    #         filtered_data.append(data[i])\n",
    "    #     else:\n",
    "    #         # Add items within epsilon distance to skip list\n",
    "    #         skip_indices.update(close_items)\n",
    "    #         skip_indices.add(i)\n",
    "    # \n",
    "    # return filtered_data\n",
    "    \n",
    "    groups = []\n",
    "    grouped_indices = set()\n",
    "\n",
    "    for i, item in enumerate(parsed_data):\n",
    "        if i in grouped_indices:\n",
    "            continue\n",
    "\n",
    "        # Start a new group with the current item\n",
    "        current_group = [data[i]]\n",
    "        grouped_indices.add(i)\n",
    "\n",
    "        # Find all descriptions within epsilon distance in avg_x\n",
    "        for j, other in enumerate(parsed_data):\n",
    "            if j != i and j not in grouped_indices and abs(item[\"avg_x\"] - other[\"avg_x\"]) <= epsilon:\n",
    "                current_group.append(data[j])\n",
    "                grouped_indices.add(j)\n",
    "\n",
    "        # Add the group to the list of groups\n",
    "        groups.append(current_group)\n",
    "\n",
    "    return groups\n",
    "    \n",
    "del data['books'][0]\n",
    "epsilon = 10\n",
    "grouped = group_vertical_lines(data['books'], epsilon)\n",
    "\n",
    "\n",
    "titles = []\n",
    "for group in grouped:\n",
    "    current_title = []\n",
    "    for item in group:\n",
    "        current_title.append(item['description'])\n",
    "    titles.append(' '.join(current_title))\n",
    "    \n",
    "for title in titles:\n",
    "    print(title)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:41.691647Z",
     "start_time": "2024-11-02T11:53:41.683126Z"
    }
   },
   "id": "16288455b1b1d879"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group 1:\n",
      "  - ND\n",
      "\n",
      "Group 2:\n",
      "  - FLOPO021\n",
      "\n",
      "Group 3:\n",
      "  - 2\n",
      "  - =\n",
      "\n",
      "Group 4:\n",
      "  - ND\n",
      "\n",
      "Group 5:\n",
      "  - RJÆTTET\n",
      "  - 38.79\n",
      "\n",
      "Group 6:\n",
      "  - Stærkere\n",
      "\n",
      "Group 7:\n",
      "  - samvær\n",
      "  - med\n",
      "  - højtlæsning\n",
      "\n",
      "Group 8:\n",
      "  - 99.1\n",
      "\n",
      "Group 9:\n",
      "  - Peter\n",
      "  - Durrie\n",
      "\n",
      "Group 10:\n",
      "  - Lillan\n",
      "  - Dusinet\n",
      "  - futo\n",
      "\n",
      "Group 11:\n",
      "  - Albeck\n",
      "  - L.\n",
      "  - G.\n",
      "  - Davis\n",
      "  - :\n",
      "  - Barnepigen\n",
      "\n",
      "Group 12:\n",
      "  - Mase\n",
      "\n",
      "Group 13:\n",
      "  - Albeck\n",
      "  - EN\n",
      "\n",
      "Group 14:\n",
      "  - FENGSIEN\n",
      "\n",
      "Group 15:\n",
      "  - Sussi\n",
      "\n",
      "Group 16:\n",
      "  - Abeck\n",
      "  - 96.7\n",
      "\n",
      "Group 17:\n",
      "  - 9'7\n",
      "\n",
      "Group 18:\n",
      "  - Gertrud\n",
      "\n",
      "Group 19:\n",
      "  - Hellbrand\n",
      "  - :\n",
      "  - Rød\n",
      "  - hibiscus\n",
      "\n",
      "Group 20:\n",
      "  - 96.7\n",
      "\n",
      "Group 21:\n",
      "  - 04.3\n",
      "\n",
      "Group 22:\n",
      "  - Georgette\n",
      "\n",
      "Group 23:\n",
      "  - Heyer\n",
      "  - :\n",
      "  - Fine\n",
      "\n",
      "Group 24:\n",
      "  - fornemmelser\n",
      "  - Kurt\n",
      "  - Vo\n",
      "\n",
      "Group 25:\n",
      "  - 98.29\n",
      "\n",
      "Group 26:\n",
      "  - Junichiro\n",
      "  - Tanizaki\n",
      "  - :\n",
      "  - Til\n",
      "  - skyggernes\n",
      "  - pris\n",
      "\n",
      "Group 27:\n",
      "  - 64.7\n",
      "  - Pernille\n",
      "  - Oldgaard\n",
      "  - :\n",
      "  - Overblik\n",
      "\n",
      "Group 28:\n",
      "  - 61.4\n",
      "\n",
      "Group 29:\n",
      "  - Praksisforskning\n",
      "  - på\n",
      "  - sundhedsområdet\n",
      "  - 83.8\n",
      "  - Kurt\n",
      "  - Vonnes\n",
      "\n",
      "Group 30:\n",
      "  - 98.218\n",
      "  - Puk\n",
      "  - Damsgård\n",
      "  - Andersen\n",
      "  - :\n",
      "  - Drageland\n",
      "  - 13.16\n",
      "  - Nick\n",
      "\n",
      "Group 31:\n",
      "  - ng\n",
      "\n",
      "Group 32:\n",
      "  - magic\n",
      "\n",
      "Group 33:\n",
      "  - of\n",
      "\n",
      "Group 34:\n",
      "  - tidying\n",
      "  - 99.4\n",
      "  - Kløvedal\n",
      "  - ,\n",
      "  - Lærke\n",
      "  - Lærke\n",
      "  - Kløvedal\n",
      "  - :\n",
      "  - Sømærke\n",
      "  - 78.797\n",
      "  - Inger\n",
      "  - laus\n",
      "\n",
      "Group 35:\n",
      "  - up\n",
      "\n",
      "Group 36:\n",
      "  - 67.7\n",
      "\n",
      "Group 37:\n",
      "  - 13.16\n",
      "  - Nicklas\n",
      "  - Brendborg\n",
      "  - :\n",
      "  - Vanedyr\n",
      "\n",
      "Group 38:\n",
      "  - J.P.\n",
      "  - Jacobsen\n",
      "  - N\n",
      "\n",
      "Group 39:\n",
      "  - Jodi\n",
      "  - Thomas\n",
      "  - RANSOM\n",
      "  - CANYON\n",
      "  - 1\n",
      "  - Mads\n",
      "  - Anand\n",
      "\n",
      "Group 40:\n",
      "  - 83.8\n",
      "  - Sylvia\n",
      "  - Plath\n",
      "  - :\n",
      "  - The\n",
      "  - bell\n",
      "  - jar\n",
      "\n",
      "Group 41:\n",
      "  - Colleen\n",
      "  - Hoover\n",
      "  - :\n",
      "  - De\n",
      "\n",
      "Group 42:\n",
      "  - 37.14796\n",
      "  - Idræt\n",
      "  - i\n",
      "  - skolen\n",
      "  - 99.4\n",
      "  - E\n",
      "\n",
      "Group 43:\n",
      "  - COBOLT\n",
      "\n",
      "Group 44:\n",
      "  - Klara\n",
      "  - Witt\n",
      "  - :\n",
      "  - Jeg\n",
      "  - finder\n",
      "  - dig\n",
      "  - i\n",
      "  - Rom\n",
      "\n",
      "Group 45:\n",
      "  - 85.3\n",
      "\n",
      "Group 46:\n",
      "  - rig\n",
      "\n",
      "Group 47:\n",
      "  - nok\n",
      "\n",
      "Group 48:\n",
      "  - 46.4\n",
      "  - Samsø\n",
      "  - 111\n",
      "  - steder\n",
      "  - på\n",
      "  - Samsø\n",
      "  - som\n",
      "  - du\n",
      "  - skal\n",
      "  - se\n",
      "\n",
      "Group 49:\n",
      "  - 99.4\n",
      "  - Mu\n",
      "\n",
      "Group 50:\n",
      "  - 83\n",
      "  - 83\n",
      "  - Barbara\n",
      "  - Kingsolver\n",
      "  - :\n",
      "  - Demon\n",
      "  - Copperhead\n",
      "\n",
      "Group 51:\n",
      "  - ark\n",
      "  - 76.235\n",
      "\n",
      "Group 52:\n",
      "  - 37.363\n",
      "  - Karina\n",
      "  - Engelund\n",
      "  - Mathiasen\n",
      "  - :\n",
      "  - Fra\n",
      "  - specialpædagogik\n",
      "  - til\n",
      "  - pædagogik\n",
      "  - 74.6\n",
      "\n",
      "Group 53:\n",
      "  - 38.44\n",
      "  - Sundhedsfremme\n",
      "  - ,\n",
      "  - forebyggelse\n",
      "  - og\n",
      "  - rehabilitering\n",
      "\n",
      "Group 54:\n",
      "  - 83.8\n",
      "  - Emil\n",
      "  - Ferris\n",
      "  - :\n",
      "  - My\n",
      "  - favorite\n",
      "  - thing\n",
      "  - is\n",
      "  - monsters\n",
      "  - Book\n",
      "  - 2\n",
      "  - Hallgrímur\n",
      "\n",
      "Group 55:\n",
      "  - andede\n",
      "  - barn\n",
      "  - Julia\n",
      "  - Tuvesson\n",
      "  - :\n",
      "  - Tomat\n",
      "  - ,\n",
      "  - tomat\n",
      "\n",
      "Group 56:\n",
      "  - 64.17\n",
      "\n",
      "Group 57:\n",
      "  - Christina\n",
      "  - He\n",
      "\n",
      "Group 58:\n",
      "  - Rebecca\n",
      "  - Yarros\n",
      "  - :\n",
      "  - Fourth\n",
      "  - wing\n",
      "  - Solvej\n",
      "  - Ba\n",
      "\n",
      "Group 59:\n",
      "  - 78.652\n",
      "  - Carl\n",
      "  - Orff\n",
      "  - Carmina\n",
      "  - burana\n",
      "\n",
      "Group 60:\n",
      "  - Nedrejord\n",
      "  - :\n",
      "  - Forbryder\n",
      "  - og\n",
      "  - straf\n",
      "  - Sh\n",
      "  - 78.797\n",
      "  - Abba\n",
      "  - ABBA\n",
      "  - CAPPELLA\n",
      "\n",
      "Group 61:\n",
      "  - Kathrine\n",
      "  - 72\n",
      "  - Strøbek\n",
      "  - .\n",
      "  - Niels\n",
      "  - Niels\n",
      "  - Strø\n",
      "\n",
      "Group 62:\n",
      "  - UVIRKELIGHEDER\n",
      "\n",
      "Group 63:\n",
      "  - Det\n",
      "  - Kronede\n",
      "  - Hjerte\n",
      "  - /\n",
      "  - Bind\n",
      "  - 2\n",
      "  - 78.18\n",
      "  - Deni\n",
      "\n",
      "Group 64:\n",
      "  - BACKMANN\n",
      "\n",
      "Group 65:\n",
      "  - FREDRIK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import json\n",
    "\n",
    "with open('simple-example-2-res.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "del data['books'][0]\n",
    "\n",
    "\n",
    "def extract_coordinates(vertex_str: str) -> Tuple[float, float]:\n",
    "    \"\"\"Extract x, y coordinates from vertex string format '(x,y)'\"\"\"\n",
    "    x, y = vertex_str.strip('()').split(',')\n",
    "    return float(x), float(y)\n",
    "\n",
    "def get_bounding_box(vertices: List[str]) -> Tuple[float, float, float, float]:\n",
    "    \"\"\"Calculate bounding box (min_x, max_x, min_y, max_y) from vertices\"\"\"\n",
    "    coords = [extract_coordinates(v) for v in vertices]\n",
    "    xs, ys = zip(*coords)\n",
    "    return min(xs), max(xs), min(ys), max(ys)\n",
    "\n",
    "def are_vertically_aligned(box1: Dict, box2: Dict, epsilon: float) -> bool:\n",
    "    \"\"\"Check if two boxes are vertically aligned within epsilon distance\"\"\"\n",
    "    # Get bounding boxes\n",
    "    box1_minx, box1_maxx, _, _ = get_bounding_box(box1['vertices'])\n",
    "    box2_minx, box2_maxx, _, _ = get_bounding_box(box2['vertices'])\n",
    "    \n",
    "    # Calculate center x coordinates\n",
    "    center1 = (box1_minx + box1_maxx) / 2\n",
    "    center2 = (box2_minx + box2_maxx) / 2\n",
    "    \n",
    "    # Check if centers are within epsilon distance\n",
    "    return abs(center1 - center2) <= epsilon\n",
    "\n",
    "def group_aligned_objects(data: List[Dict], epsilon: float) -> List[List[Dict]]:\n",
    "    \"\"\"\n",
    "    Group objects that are vertically aligned within epsilon distance\n",
    "    \n",
    "    Args:\n",
    "        data: List of dictionaries containing vertices and descriptions\n",
    "        epsilon: Maximum allowed distance between aligned objects\n",
    "        \n",
    "    Returns:\n",
    "        List of groups, where each group is a list of aligned objects\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return []\n",
    "    \n",
    "    # Initialize groups\n",
    "    groups = []\n",
    "    used = set()\n",
    "    \n",
    "    for i, obj1 in enumerate(data):\n",
    "        if i in used:\n",
    "            continue\n",
    "            \n",
    "        # Start a new group with current object\n",
    "        current_group = [obj1]\n",
    "        used.add(i)\n",
    "        \n",
    "        # Check remaining objects\n",
    "        for j, obj2 in enumerate(data):\n",
    "            if j in used:\n",
    "                continue\n",
    "                \n",
    "            # Check if obj2 is aligned with any object in current group\n",
    "            if any(are_vertically_aligned(existing_obj, obj2, epsilon) \n",
    "                  for existing_obj in current_group):\n",
    "                current_group.append(obj2)\n",
    "                used.add(j)\n",
    "        \n",
    "        groups.append(current_group)\n",
    "    \n",
    "    # Sort groups by vertical position (top to bottom)\n",
    "    for group in groups:\n",
    "        group.sort(key=lambda x: float(extract_coordinates(x['vertices'][0])[1]))\n",
    "    \n",
    "    # Sort groups by leftmost x-coordinate\n",
    "    groups.sort(key=lambda g: float(extract_coordinates(g[0]['vertices'][0])[0]))\n",
    "    \n",
    "    return groups\n",
    "\n",
    "# Example usage\n",
    "epsilon = 10  # Adjust this value based on your needs\n",
    "grouped_objects = group_aligned_objects(data['books'], epsilon)\n",
    "\n",
    "# Print results\n",
    "for i, group in enumerate(grouped_objects):\n",
    "    print(f\"\\nGroup {i + 1}:\")\n",
    "    for obj in group:\n",
    "        print(f\"  - {obj['description']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-03T15:00:04.365165Z",
     "start_time": "2024-11-03T15:00:04.289622Z"
    }
   },
   "id": "5509be8819c3a485"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group 1:\n",
      "  ark (y=0.0)\n",
      "\n",
      "Group 2:\n",
      "  andede (y=0.0)\n",
      "  barn (y=140.0)\n",
      "\n",
      "Group 3:\n",
      "  rig (y=0.0)\n",
      "  nok (y=54.0)\n",
      "\n",
      "Group 4:\n",
      "  ng (y=0.0)\n",
      "  magic (y=40.0)\n",
      "  of (y=136.0)\n",
      "  tidying (y=170.0)\n",
      "  up (y=277.0)\n",
      "\n",
      "Group 5:\n",
      "  ND (y=0.0)\n",
      "\n",
      "Group 6:\n",
      "  RJÆTTET (y=9.0)\n",
      "\n",
      "Group 7:\n",
      "  FLOPO021 (y=61.0)\n",
      "\n",
      "Group 8:\n",
      "  COBOLT (y=191.0)\n",
      "\n",
      "Group 9:\n",
      "  83.8 (y=995.0)\n",
      "  Emil (y=1148.0)\n",
      "  Ferris (y=1233.0)\n",
      "  : (y=1329.0)\n",
      "  My (y=1351.0)\n",
      "  favorite (y=1405.0)\n",
      "  thing (y=1538.0)\n",
      "  is (y=1632.0)\n",
      "  monsters (y=1670.0)\n",
      "  Book (y=1827.0)\n",
      "  2 (y=1914.0)\n",
      "\n",
      "Group 10:\n",
      "  38.44 (y=1103.0)\n",
      "  Sundhedsfremme (y=1254.0)\n",
      "  , (y=1548.0)\n",
      "  forebyggelse (y=1564.0)\n",
      "  og (y=1784.0)\n",
      "  rehabilitering (y=1833.0)\n",
      "\n",
      "Group 11:\n",
      "  Abeck (y=1113.0)\n",
      "  Sussi (y=1118.0)\n",
      "\n",
      "Group 12:\n",
      "  38.79 (y=1119.0)\n",
      "  Stærkere (y=1269.0)\n",
      "  samvær (y=1381.0)\n",
      "  med (y=1482.0)\n",
      "  højtlæsning (y=1537.0)\n",
      "\n",
      "Group 13:\n",
      "  Albeck (y=1130.0)\n",
      "  Mase (y=1136.0)\n",
      "\n",
      "Group 14:\n",
      "  37.363 (y=1135.0)\n",
      "  Karina (y=1287.0)\n",
      "  Engelund (y=1370.0)\n",
      "  Mathiasen (y=1488.0)\n",
      "  : (y=1605.0)\n",
      "  Fra (y=1619.0)\n",
      "  specialpædagogik (y=1662.0)\n",
      "  til (y=1870.0)\n",
      "  pædagogik (y=1897.0)\n",
      "\n",
      "Group 15:\n",
      "  Albeck (y=1152.0)\n",
      "  Lillan (y=1158.0)\n",
      "\n",
      "Group 16:\n",
      "  37.14796 (y=1153.0)\n",
      "  Idræt (y=1302.0)\n",
      "  i (y=1397.0)\n",
      "  skolen (y=1415.0)\n",
      "\n",
      "Group 17:\n",
      "  83 (y=1155.0)\n",
      "  83 (y=1156.0)\n",
      "  Barbara (y=1305.0)\n",
      "  Kingsolver (y=1441.0)\n",
      "  : (y=1614.0)\n",
      "  Demon (y=1635.0)\n",
      "  Copperhead (y=1754.0)\n",
      "\n",
      "Group 18:\n",
      "  64.17 (y=1166.0)\n",
      "  Julia (y=1316.0)\n",
      "  Tuvesson (y=1405.0)\n",
      "  : (y=1566.0)\n",
      "  Tomat (y=1584.0)\n",
      "  , (y=1687.0)\n",
      "  tomat (y=1703.0)\n",
      "\n",
      "Group 19:\n",
      "  98.218 (y=1185.0)\n",
      "  Puk (y=1337.0)\n",
      "  Damsgård (y=1408.0)\n",
      "  Andersen (y=1584.0)\n",
      "  : (y=1741.0)\n",
      "  Drageland (y=1761.0)\n",
      "\n",
      "Group 20:\n",
      "  61.4 (y=1203.0)\n",
      "  Praksisforskning (y=1354.0)\n",
      "  på (y=1557.0)\n",
      "  sundhedsområdet (y=1591.0)\n",
      "\n",
      "Group 21:\n",
      "  Rebecca (y=1206.0)\n",
      "  Yarros (y=1355.0)\n",
      "  : (y=1461.0)\n",
      "  Fourth (y=1480.0)\n",
      "  wing (y=1588.0)\n",
      "\n",
      "Group 22:\n",
      "  13.16 (y=1221.0)\n",
      "  Nicklas (y=1367.0)\n",
      "  Brendborg (y=1496.0)\n",
      "  : (y=1669.0)\n",
      "  Vanedyr (y=1687.0)\n",
      "\n",
      "Group 23:\n",
      "  FENGSIEN (y=1237.0)\n",
      "  EN (y=1250.0)\n",
      "  9'7 (y=1286.0)\n",
      "\n",
      "Group 24:\n",
      "  Jodi (y=1242.0)\n",
      "  Thomas (y=1362.0)\n",
      "  RANSOM (y=1571.0)\n",
      "  CANYON (y=1810.0)\n",
      "  1 (y=2058.0)\n",
      "\n",
      "Group 25:\n",
      "  99.1 (y=1262.0)\n",
      "\n",
      "Group 26:\n",
      "  Georgette (y=1263.0)\n",
      "  Heyer (y=1437.0)\n",
      "  : (y=1532.0)\n",
      "  Fine (y=1553.0)\n",
      "  fornemmelser (y=1628.0)\n",
      "\n",
      "Group 27:\n",
      "  Gertrud (y=1263.0)\n",
      "  Hellbrand (y=1399.0)\n",
      "  : (y=1556.0)\n",
      "  Rød (y=1576.0)\n",
      "  hibiscus (y=1653.0)\n",
      "\n",
      "Group 28:\n",
      "  L. (y=1266.0)\n",
      "  G. (y=1305.0)\n",
      "  Davis (y=1356.0)\n",
      "  : (y=1447.0)\n",
      "  Barnepigen (y=1469.0)\n",
      "  Dusinet (y=1561.0)\n",
      "  futo (y=1640.0)\n",
      "\n",
      "Group 29:\n",
      "  64.7 (y=1295.0)\n",
      "  Pernille (y=1444.0)\n",
      "  Oldgaard (y=1575.0)\n",
      "  : (y=1723.0)\n",
      "  Overblik (y=1742.0)\n",
      "\n",
      "Group 30:\n",
      "  46.4 (y=1307.0)\n",
      "  Samsø (y=1393.0)\n",
      "  111 (y=1544.0)\n",
      "  steder (y=1607.0)\n",
      "  på (y=1716.0)\n",
      "  Samsø (y=1762.0)\n",
      "  som (y=1877.0)\n",
      "  du (y=1952.0)\n",
      "  skal (y=1999.0)\n",
      "  se (y=2070.0)\n",
      "\n",
      "Group 31:\n",
      "  99.4 (y=1330.0)\n",
      "  Kløvedal (y=1416.0)\n",
      "  , (y=1561.0)\n",
      "  Lærke (y=1578.0)\n",
      "  Lærke (y=1715.0)\n",
      "  Kløvedal (y=1823.0)\n",
      "  : (y=1960.0)\n",
      "  Sømærke (y=1977.0)\n",
      "\n",
      "Group 32:\n",
      "  83.8 (y=1339.0)\n",
      "  Sylvia (y=1479.0)\n",
      "  Plath (y=1585.0)\n",
      "  : (y=1662.0)\n",
      "  The (y=1681.0)\n",
      "  bell (y=1748.0)\n",
      "  jar (y=1808.0)\n",
      "\n",
      "Group 33:\n",
      "  Peter (y=1411.0)\n",
      "  Durrie (y=1467.0)\n",
      "\n",
      "Group 34:\n",
      "  Kathrine (y=1412.0)\n",
      "  Nedrejord (y=1551.0)\n",
      "  : (y=1701.0)\n",
      "  Forbryder (y=1720.0)\n",
      "  og (y=1873.0)\n",
      "  straf (y=1916.0)\n",
      "\n",
      "Group 35:\n",
      "  2 (y=1412.0)\n",
      "  = (y=1457.0)\n",
      "\n",
      "Group 36:\n",
      "  Klara (y=1427.0)\n",
      "  Witt (y=1490.0)\n",
      "  : (y=1536.0)\n",
      "  Jeg (y=1549.0)\n",
      "  finder (y=1594.0)\n",
      "  dig (y=1666.0)\n",
      "  i (y=1707.0)\n",
      "  Rom (y=1721.0)\n",
      "\n",
      "Group 37:\n",
      "  98.29 (y=1450.0)\n",
      "  Junichiro (y=1595.0)\n",
      "  Tanizaki (y=1707.0)\n",
      "  : (y=1800.0)\n",
      "  Til (y=1813.0)\n",
      "  skyggernes (y=1846.0)\n",
      "  pris (y=1978.0)\n",
      "\n",
      "Group 38:\n",
      "  ND (y=1873.0)\n",
      "\n",
      "Group 39:\n",
      "  Sh (y=2529.0)\n",
      "  78.652 (y=2587.0)\n",
      "  78.797 (y=2597.0)\n",
      "  Carl (y=2679.0)\n",
      "  Abba (y=2690.0)\n",
      "  Orff (y=2735.0)\n",
      "  72 (y=2744.0)\n",
      "  Strøbek (y=2771.0)\n",
      "  ABBA (y=2789.0)\n",
      "  Carmina (y=2811.0)\n",
      "  . (y=2842.0)\n",
      "  CAPPELLA (y=2852.0)\n",
      "  Niels (y=2854.0)\n",
      "  burana (y=2907.0)\n",
      "  Niels (y=2928.0)\n",
      "  Strø (y=2984.0)\n",
      "\n",
      "Group 40:\n",
      "  Det (y=2602.0)\n",
      "  Kronede (y=2635.0)\n",
      "  Hjerte (y=2710.0)\n",
      "  / (y=2766.0)\n",
      "  Bind (y=2778.0)\n",
      "  2 (y=2821.0)\n",
      "  UVIRKELIGHEDER (y=2888.0)\n",
      "  78.18 (y=2911.0)\n",
      "  Deni (y=2988.0)\n",
      "\n",
      "Group 41:\n",
      "  J.P. (y=2819.0)\n",
      "  Jacobsen (y=2865.0)\n",
      "  N (y=3002.0)\n",
      "\n",
      "Group 42:\n",
      "  Colleen (y=2840.0)\n",
      "  Hoover (y=2917.0)\n",
      "  : (y=2985.0)\n",
      "  De (y=2997.0)\n",
      "\n",
      "Group 43:\n",
      "  83.8 (y=2846.0)\n",
      "  Kurt (y=2918.0)\n",
      "  Vonnes (y=2964.0)\n",
      "\n",
      "Group 44:\n",
      "  FREDRIK (y=2853.0)\n",
      "  BACKMANN (y=2898.0)\n",
      "\n",
      "Group 45:\n",
      "  13.16 (y=2853.0)\n",
      "  Nick (y=2967.0)\n",
      "\n",
      "Group 46:\n",
      "  78.797 (y=2857.0)\n",
      "  Inger (y=2945.0)\n",
      "  67.7 (y=2976.0)\n",
      "  laus (y=2990.0)\n",
      "\n",
      "Group 47:\n",
      "  Hallgrímur (y=2882.0)\n",
      "\n",
      "Group 48:\n",
      "  Christina (y=2891.0)\n",
      "  He (y=3001.0)\n",
      "\n",
      "Group 49:\n",
      "  Mads (y=2921.0)\n",
      "  Anand (y=2972.0)\n",
      "\n",
      "Group 50:\n",
      "  Solvej (y=2940.0)\n",
      "  Ba (y=3005.0)\n",
      "\n",
      "Group 51:\n",
      "  Kurt (y=2946.0)\n",
      "  Vo (y=2993.0)\n",
      "\n",
      "Group 52:\n",
      "  96.7 (y=2950.0)\n",
      "\n",
      "Group 53:\n",
      "  99.4 (y=2953.0)\n",
      "  Mu (y=2996.0)\n",
      "\n",
      "Group 54:\n",
      "  74.6 (y=2955.0)\n",
      "\n",
      "Group 55:\n",
      "  99.4 (y=2968.0)\n",
      "  E (y=3014.0)\n",
      "\n",
      "Group 56:\n",
      "  76.235 (y=2971.0)\n",
      "\n",
      "Group 57:\n",
      "  96.7 (y=2975.0)\n",
      "\n",
      "Group 58:\n",
      "  85.3 (y=2982.0)\n",
      "\n",
      "Group 59:\n",
      "  04.3 (y=2995.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "\n",
    "with open('simple-example-2-res.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "del data['books'][0]\n",
    "\n",
    "@dataclass\n",
    "class BoundingBox:\n",
    "    min_x: float\n",
    "    max_x: float\n",
    "    min_y: float\n",
    "    max_y: float\n",
    "    center_x: float\n",
    "    center_y: float\n",
    "    height: float\n",
    "\n",
    "def extract_coordinates(vertex_str: str) -> Tuple[float, float]:\n",
    "    \"\"\"Extract x, y coordinates from vertex string format '(x,y)'\"\"\"\n",
    "    x, y = vertex_str.strip('()').split(',')\n",
    "    return float(x), float(y)\n",
    "\n",
    "def get_bounding_box(vertices: List[str]) -> BoundingBox:\n",
    "    \"\"\"Calculate bounding box with additional metrics from vertices\"\"\"\n",
    "    coords = [extract_coordinates(v) for v in vertices]\n",
    "    xs, ys = zip(*coords)\n",
    "    min_x, max_x = min(xs), max(xs)\n",
    "    min_y, max_y = min(ys), max(ys)\n",
    "    center_x = (min_x + max_x) / 2\n",
    "    center_y = (min_y + max_y) / 2\n",
    "    height = max_y - min_y\n",
    "    return BoundingBox(min_x, max_x, min_y, max_y, center_x, center_y, height)\n",
    "\n",
    "def should_be_grouped(obj1: Dict, obj2: Dict, \n",
    "                     horizontal_epsilon: float,\n",
    "                     vertical_spacing_factor: float) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if two objects should be grouped based on both alignment and spacing\n",
    "    \n",
    "    Args:\n",
    "        obj1, obj2: Dictionary objects containing vertices and descriptions\n",
    "        horizontal_epsilon: Maximum allowed horizontal distance between objects\n",
    "        vertical_spacing_factor: Maximum allowed vertical spacing as a factor of text height\n",
    "    \"\"\"\n",
    "    box1 = get_bounding_box(obj1['vertices'])\n",
    "    box2 = get_bounding_box(obj2['vertices'])\n",
    "    \n",
    "    # Check horizontal alignment\n",
    "    horizontal_aligned = abs(box1.center_x - box2.center_x) <= horizontal_epsilon\n",
    "    \n",
    "    # Check vertical spacing\n",
    "    avg_height = (box1.height + box2.height) / 2\n",
    "    max_vertical_spacing = avg_height * vertical_spacing_factor\n",
    "    \n",
    "    vertical_distance = min(\n",
    "        abs(box1.max_y - box2.min_y),\n",
    "        abs(box2.max_y - box1.min_y)\n",
    "    )\n",
    "    \n",
    "    close_enough = vertical_distance <= max_vertical_spacing\n",
    "    \n",
    "    # Check if one object is numerical (like \"83\")\n",
    "    is_number = lambda s: s.replace('.', '').isdigit()\n",
    "    one_is_number = (is_number(obj1['description']) or \n",
    "                    is_number(obj2['description']))\n",
    "    \n",
    "    # If one is a number, be more lenient with vertical spacing\n",
    "    if one_is_number:\n",
    "        max_vertical_spacing *= 1.5\n",
    "        close_enough = vertical_distance <= max_vertical_spacing\n",
    "    \n",
    "    return horizontal_aligned and close_enough\n",
    "\n",
    "def group_related_text(data: List[Dict], \n",
    "                      horizontal_epsilon: float = 50,\n",
    "                      vertical_spacing_factor: float = 1.5) -> List[List[Dict]]:\n",
    "    \"\"\"\n",
    "    Group related text objects based on spatial relationship and content type\n",
    "    \n",
    "    Args:\n",
    "        data: List of dictionaries containing vertices and descriptions\n",
    "        horizontal_epsilon: Maximum allowed horizontal distance between objects\n",
    "        vertical_spacing_factor: Maximum allowed vertical spacing as a factor of text height\n",
    "        \n",
    "    Returns:\n",
    "        List of groups, where each group contains related text objects\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return []\n",
    "    \n",
    "    # Sort data by vertical position (top to bottom)\n",
    "    sorted_data = sorted(data, \n",
    "                        key=lambda x: get_bounding_box(x['vertices']).min_y)\n",
    "    \n",
    "    groups = []\n",
    "    used = set()\n",
    "    \n",
    "    for i, obj1 in enumerate(sorted_data):\n",
    "        if i in used:\n",
    "            continue\n",
    "            \n",
    "        current_group = [obj1]\n",
    "        used.add(i)\n",
    "        \n",
    "        # Look at subsequent objects for potential grouping\n",
    "        for j in range(i + 1, len(sorted_data)):\n",
    "            if j in used:\n",
    "                continue\n",
    "                \n",
    "            obj2 = sorted_data[j]\n",
    "            \n",
    "            # Check if obj2 should be grouped with any object in current_group\n",
    "            if any(should_be_grouped(existing_obj, obj2, \n",
    "                                   horizontal_epsilon, vertical_spacing_factor)\n",
    "                  for existing_obj in current_group):\n",
    "                current_group.append(obj2)\n",
    "                used.add(j)\n",
    "        \n",
    "        groups.append(current_group)\n",
    "    \n",
    "    # Sort objects within each group by vertical position\n",
    "    for group in groups:\n",
    "        group.sort(key=lambda x: get_bounding_box(x['vertices']).min_y)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "# Example usage and output formatting\n",
    "def print_grouped_text(groups: List[List[Dict]]):\n",
    "    \"\"\"Print grouped text in a readable format\"\"\"\n",
    "    for i, group in enumerate(groups, 1):\n",
    "        print(f\"\\nGroup {i}:\")\n",
    "        for item in group:\n",
    "            box = get_bounding_box(item['vertices'])\n",
    "            print(f\"  {item['description']} (y={box.min_y:.1f})\")\n",
    "            \n",
    "            \n",
    "            \n",
    "# Adjust these parameters based on your needs\n",
    "groups = group_related_text(\n",
    "    data['books'],\n",
    "    horizontal_epsilon=50,  # Maximum horizontal difference\n",
    "    vertical_spacing_factor=1.5  # Maximum vertical spacing as factor of text height\n",
    ")\n",
    "\n",
    "print_grouped_text(groups)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T12:46:49.950740Z",
     "start_time": "2024-11-05T12:46:49.837876Z"
    }
   },
   "id": "586a0ccc60430287"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
